{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autots in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (0.6.9)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from autots) (1.26.3)\n",
      "Requirement already satisfied: pandas>=0.25.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from autots) (2.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.10.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from autots) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from autots) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas>=0.25.0->autots) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas>=0.25.0->autots) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas>=0.25.0->autots) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from scikit-learn>=0.20.0->autots) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from scikit-learn>=0.20.0->autots) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from scikit-learn>=0.20.0->autots) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels>=0.10.0->autots) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels>=0.10.0->autots) (23.2)\n",
      "Requirement already satisfied: six in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from patsy>=0.5.4->statsmodels>=0.10.0->autots) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels) (1.12.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in c:\\users\\jhivan\\miniconda3\\envs\\ensemble\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autots\n",
    "%pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # also: _hourly, _daily, _weekly, or _yearly\n",
    "# from autots.datasets import load_monthly\n",
    "\n",
    "# df_long = load_monthly(long=True)\n",
    "\n",
    "# from autots import AutoTS\n",
    "\n",
    "# model = AutoTS(\n",
    "#     forecast_length=3,\n",
    "#     frequency='infer',\n",
    "#     ensemble='simple',\n",
    "#     max_generations=5,\n",
    "#     num_validations=2,\n",
    "# )\n",
    "# model = model.fit(df_long, date_col='datetime', value_col='value', id_col='series_id')\n",
    "\n",
    "# # Print the description of the best model\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on AutoTS in module autots.evaluator.auto_ts object:\n",
      "\n",
      "class AutoTS(builtins.object)\n",
      " |  AutoTS(forecast_length: int = 14, frequency: str = 'infer', prediction_interval: float = 0.9, max_generations: int = 10, no_negatives: bool = False, constraint: float = None, ensemble: str = None, initial_template: str = 'General+Random', random_seed: int = 2022, holiday_country: str = 'US', subset: int = None, aggfunc: str = 'first', na_tolerance: float = 1, metric_weighting: dict = {'smape_weighting': 5, 'mae_weighting': 2, 'rmse_weighting': 2, 'made_weighting': 0.5, 'mage_weighting': 0, 'mle_weighting': 0, 'imle_weighting': 0, 'spl_weighting': 3, 'containment_weighting': 0, 'contour_weighting': 1, 'runtime_weighting': 0.05, 'oda_weighting': 0.001}, drop_most_recent: int = 0, drop_data_older_than_periods: int = None, model_list: str = 'default', transformer_list: dict = 'auto', transformer_max_depth: int = 6, models_mode: str = 'random', num_validations: int = 'auto', models_to_validate: float = 0.15, max_per_model_class: int = None, validation_method: str = 'backwards', min_allowed_train_percent: float = 0.5, remove_leading_zeroes: bool = False, prefill_na: str = None, introduce_na: bool = None, preclean: dict = None, model_interrupt: bool = True, generation_timeout: int = None, current_model_file: str = None, force_gc: bool = False, verbose: int = 1, n_jobs: int = -2)\n",
      " |  \n",
      " |  Automate time series modeling using a genetic algorithm.\n",
      " |  \n",
      " |  Args:\n",
      " |      forecast_length (int): number of periods over which to evaluate forecast. Can be overriden later in .predict().\n",
      " |          when you don't have much historical data, using a small forecast length for .fit and the full desired forecast lenght for .predict is usually the best possible approach given limitations.\n",
      " |      frequency (str): 'infer' or a specific pandas datetime offset. Can be used to force rollup of data (ie daily input, but frequency 'M' will rollup to monthly).\n",
      " |      prediction_interval (float): 0-1, uncertainty range for upper and lower forecasts. Adjust range, but rarely matches actual containment.\n",
      " |      max_generations (int): number of genetic algorithms generations to run.\n",
      " |          More runs = longer runtime, generally better accuracy.\n",
      " |          It's called `max` because someday there will be an auto early stopping option, but for now this is just the exact number of generations to run.\n",
      " |      no_negatives (bool): if True, all negative predictions are rounded up to 0.\n",
      " |      constraint (float): when not None, use this float value * data st dev above max or below min for constraining forecast values.\n",
      " |          now also instead accepts a dictionary containing the following key/values:\n",
      " |              constraint_method (str): one of\n",
      " |                  stdev_min - threshold is min and max of historic data +/- constraint * st dev of data\n",
      " |                  stdev - threshold is the mean of historic data +/- constraint * st dev of data\n",
      " |                  absolute - input is array of length series containing the threshold's final value for each\n",
      " |                  quantile - constraint is the quantile of historic data to use as threshold\n",
      " |              constraint_regularization (float): 0 to 1\n",
      " |                  where 0 means no constraint, 1 is hard threshold cutoff, and in between is penalty term\n",
      " |              upper_constraint (float): or array, depending on method, None if unused\n",
      " |              lower_constraint (float): or array, depending on method, None if unused\n",
      " |              bounds (bool): if True, apply to upper/lower forecast, otherwise False applies only to forecast\n",
      " |      ensemble (str): None or list or comma-separated string containing:\n",
      " |          'auto', 'simple', 'distance', 'horizontal', 'horizontal-min', 'horizontal-max', \"mosaic\", \"subsample\"\n",
      " |      initial_template (str): 'Random' - randomly generates starting template, 'General' uses template included in package, 'General+Random' - both of previous. Also can be overriden with self.import_template()\n",
      " |      random_seed (int): random seed allows (slightly) more consistent results.\n",
      " |      holiday_country (str): passed through to Holidays package for some models.\n",
      " |      subset (int): maximum number of series to evaluate at once. Useful to speed evaluation when many series are input.\n",
      " |          takes a new subset of columns on each validation, unless mosaic ensembling, in which case columns are the same in each validation\n",
      " |      aggfunc (str): if data is to be rolled up to a higher frequency (daily -> monthly) or duplicate timestamps are included. Default 'first' removes duplicates, for rollup try 'mean' or np.sum.\n",
      " |          Beware numeric aggregations like 'mean' will not work with non-numeric inputs.\n",
      " |          Numeric aggregations like 'sum' will also change nan values to 0\n",
      " |      na_tolerance (float): 0 to 1. Series are dropped if they have more than this percent NaN. 0.95 here would allow series containing up to 95% NaN values.\n",
      " |      metric_weighting (dict): weights to assign to metrics, effecting how the ranking score is generated.\n",
      " |      drop_most_recent (int): option to drop n most recent data points. Useful, say, for monthly sales data where the current (unfinished) month is included.\n",
      " |          occurs after any aggregration is applied, so will be whatever is specified by frequency, will drop n frequencies\n",
      " |      drop_data_older_than_periods (int): take only the n most recent timestamps\n",
      " |      model_list (list): str alias or list of names of model objects to use\n",
      " |          now can be a dictionary of {\"model\": prob} but only affects starting random templates. Genetic algorithim takes from there.\n",
      " |      transformer_list (list): list of transformers to use, or dict of transformer:probability. Note this does not apply to initial templates.\n",
      " |          can accept string aliases: \"all\", \"fast\", \"superfast\", 'scalable' (scalable is a subset of fast that should have fewer memory issues at scale)\n",
      " |      transformer_max_depth (int): maximum number of sequential transformers to generate for new Random Transformers. Fewer will be faster.\n",
      " |      models_mode (str): option to adjust parameter options for newly generated models. Only sporadically utilized. Currently includes:\n",
      " |          'default'/'random', 'deep' (searches more params, likely slower), and 'regressor' (forces 'User' regressor mode in regressor capable models),\n",
      " |          'gradient_boosting', 'neuralnets' (~Regression class models only)\n",
      " |      num_validations (int): number of cross validations to perform. 0 for just train/test on best split.\n",
      " |          Possible confusion: num_validations is the number of validations to perform *after* the first eval segment, so totally eval/validations will be this + 1.\n",
      " |          Also \"auto\" and \"max\" aliases available. Max maxes out at 50.\n",
      " |      models_to_validate (int): top n models to pass through to cross validation. Or float in 0 to 1 as % of tried.\n",
      " |          0.99 is forced to 100% validation. 1 evaluates just 1 model.\n",
      " |          If horizontal or mosaic ensemble, then additional min per_series models above the number here are added to validation.\n",
      " |      max_per_model_class (int): of the models_to_validate what is the maximum to pass from any one model class/family.\n",
      " |      validation_method (str): 'even', 'backwards', or 'seasonal n' where n is an integer of seasonal\n",
      " |          'backwards' is better for recency and for shorter training sets\n",
      " |          'even' splits the data into equally-sized slices best for more consistent data, a poetic but less effective strategy than others here\n",
      " |          'seasonal' most similar indexes\n",
      " |          'seasonal n' for example 'seasonal 364' would test all data on each previous year of the forecast_length that would immediately follow the training data.\n",
      " |          'similarity' automatically finds the data sections most similar to the most recent data that will be used for prediction\n",
      " |          'custom' - if used, .fit() needs validation_indexes passed - a list of pd.DatetimeIndex's, tail of each is used as test\n",
      " |      min_allowed_train_percent (float): percent of forecast length to allow as min training, else raises error.\n",
      " |          0.5 with a forecast length of 10 would mean 5 training points are mandated, for a total of 15 points.\n",
      " |          Useful in (unrecommended) cases where forecast_length > training length.\n",
      " |      remove_leading_zeroes (bool): replace leading zeroes with NaN. Useful in data where initial zeroes mean data collection hasn't started yet.\n",
      " |      prefill_na (str): value to input to fill all NaNs with. Leaving as None and allowing model interpolation is recommended.\n",
      " |          None, 0, 'mean', or 'median'. 0 may be useful in for examples sales cases where all NaN can be assumed equal to zero.\n",
      " |      introduce_na (bool): whether to force last values in one training validation to be NaN. Helps make more robust models.\n",
      " |          defaults to None, which introduces NaN in last rows of validations if any NaN in tail of training data. Will not introduce NaN to all series if subset is used.\n",
      " |          if True, will also randomly change 20% of all rows to NaN in the validations\n",
      " |      preclean (dict): if not None, a dictionary of Transformer params to be applied to input data\n",
      " |          {\"fillna\": \"median\", \"transformations\": {}, \"transformation_params\": {}}\n",
      " |          This will change data used in model inputs for fit and predict, and for accuracy evaluation in cross validation!\n",
      " |      model_interrupt (bool): if False, KeyboardInterrupts quit entire program.\n",
      " |          if True, KeyboardInterrupts attempt to only quit current model.\n",
      " |          if True, recommend use in conjunction with `verbose` > 0 and `result_file` in the event of accidental complete termination.\n",
      " |          if \"end_generation\", as True and also ends entire generation of run. Note skipped models will not be tried again.\n",
      " |      generation_timeout (int): if not None, this is the number of minutes from start at which the generational search ends, then proceeding to validation\n",
      " |          This is only checked after the end of each generation, so only offers an 'approximate' timeout for searching. It is an overall cap for total generation search time, not per generation.\n",
      " |      current_model_file (str): file path to write to disk of current model params (for debugging if computer crashes). .json is appended\n",
      " |      force_gc (bool): if True, run gc.collect() after each model run. Probably won't make much difference.\n",
      " |      verbose (int): setting to 0 or lower should reduce most output. Higher numbers give more output.\n",
      " |      n_jobs (int): Number of cores available to pass to parallel processing. A joblib context manager can be used instead (pass None in this case). Also 'auto'.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      best_model (pd.DataFrame): DataFrame containing template for the best ranked model\n",
      " |      best_model_name (str): model name\n",
      " |      best_model_params (dict): model params\n",
      " |      best_model_transformation_params (dict): transformation parameters\n",
      " |      best_model_ensemble (int): Ensemble type int id\n",
      " |      regression_check (bool): If True, the best_model uses an input 'User' future_regressor\n",
      " |      df_wide_numeric (pd.DataFrame): dataframe containing shaped final data, will include preclean\n",
      " |      initial_results.model_results (object): contains a collection of result metrics\n",
      " |      score_per_series (pd.DataFrame): generated score of metrics given per input series, if horizontal ensembles\n",
      " |  \n",
      " |  Methods:\n",
      " |      fit, predict\n",
      " |      export_template, import_template, import_results\n",
      " |      results, failure_rate\n",
      " |      horizontal_to_df, mosaic_to_df\n",
      " |      plot_horizontal, plot_horizontal_transformers, plot_generation_loss, plot_backforecast\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, forecast_length: int = 14, frequency: str = 'infer', prediction_interval: float = 0.9, max_generations: int = 10, no_negatives: bool = False, constraint: float = None, ensemble: str = None, initial_template: str = 'General+Random', random_seed: int = 2022, holiday_country: str = 'US', subset: int = None, aggfunc: str = 'first', na_tolerance: float = 1, metric_weighting: dict = {'smape_weighting': 5, 'mae_weighting': 2, 'rmse_weighting': 2, 'made_weighting': 0.5, 'mage_weighting': 0, 'mle_weighting': 0, 'imle_weighting': 0, 'spl_weighting': 3, 'containment_weighting': 0, 'contour_weighting': 1, 'runtime_weighting': 0.05, 'oda_weighting': 0.001}, drop_most_recent: int = 0, drop_data_older_than_periods: int = None, model_list: str = 'default', transformer_list: dict = 'auto', transformer_max_depth: int = 6, models_mode: str = 'random', num_validations: int = 'auto', models_to_validate: float = 0.15, max_per_model_class: int = None, validation_method: str = 'backwards', min_allowed_train_percent: float = 0.5, remove_leading_zeroes: bool = False, prefill_na: str = None, introduce_na: bool = None, preclean: dict = None, model_interrupt: bool = True, generation_timeout: int = None, current_model_file: str = None, force_gc: bool = False, verbose: int = 1, n_jobs: int = -2)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Print.\n",
      " |  \n",
      " |  back_forecast(self, series=None, n_splits: int = 'auto', tail: int = 'auto', verbose: int = 0)\n",
      " |      Create forecasts for the historical training data, ie. backcast or back forecast. OUT OF SAMPLE\n",
      " |      \n",
      " |      This actually forecasts on historical data, these are not fit model values as are often returned by other packages.\n",
      " |      As such, this will be slower, but more representative of real world model performance.\n",
      " |      There may be jumps in data between chunks.\n",
      " |      \n",
      " |      Args are same as for model_forecast except...\n",
      " |      n_splits(int): how many pieces to split data into. Pass 2 for fastest, or \"auto\" for best accuracy\n",
      " |      series (str): if to run on only one column, pass column name. Faster than full.\n",
      " |      tail (int): df.tail() of the dataset, back_forecast is only run on n most recent observations.\n",
      " |          which points at eval_periods of lower-level back_forecast function\n",
      " |      \n",
      " |      Returns a standard prediction object (access .forecast, .lower_forecast, .upper_forecast)\n",
      " |  \n",
      " |  best_model_per_series_mape(self)\n",
      " |      This isn't quite classic mape but is a percentage mean error intended for quick visuals not final statistics (see model.results()).\n",
      " |  \n",
      " |  best_model_per_series_score(self)\n",
      " |  \n",
      " |  diagnose_params(self, target='runtime', waterfall_plots=True)\n",
      " |      Attempt to explain params causing measured outcomes using shap and linear regression coefficients.\n",
      " |      \n",
      " |      Args:\n",
      " |          target (str): runtime, smape, mae, oda, or exception, the measured outcome to correlate parameters with\n",
      " |          waterfall_plots (bool): whether to show waterfall SHAP plots\n",
      " |  \n",
      " |  expand_horizontal(self)\n",
      " |      Enables expanding horizontal models trained on a subset to full data.\n",
      " |      Reruns template models and generates new template.\n",
      " |  \n",
      " |  export_best_model(self, filename, **kwargs)\n",
      " |      Basically the same as export_template but only ever the one best model.\n",
      " |  \n",
      " |  export_template(self, filename=None, models: str = 'best', n: int = 40, max_per_model_class: int = None, include_results: bool = False, unpack_ensembles: bool = False)\n",
      " |      Export top results as a reusable template.\n",
      " |      \n",
      " |      Args:\n",
      " |          filename (str): 'csv' or 'json' (in filename).\n",
      " |              `None` to return a dataframe and not write a file.\n",
      " |          models (str): 'best' or 'all', and 'slowest' for diagnostics\n",
      " |          n (int): if models = 'best', how many n-best to export\n",
      " |          max_per_model_class (int): if models = 'best',\n",
      " |              the max number of each model class to include in template\n",
      " |          include_results (bool): whether to include performance metrics\n",
      " |          unpack_ensembles (bool): if True, ensembles are returned only as components (will result in larger n models, as full ensemble counts as 1 model)\n",
      " |  \n",
      " |  failure_rate(self, result_set: str = 'initial')\n",
      " |      Return fraction of models passing with exceptions.\n",
      " |      \n",
      " |      Args:\n",
      " |          result_set (str, optional): 'validation' or 'initial'. Defaults to 'initial'.\n",
      " |      \n",
      " |      Returns:\n",
      " |          float.\n",
      " |  \n",
      " |  fit(self, df, date_col: str = None, value_col: str = None, id_col: str = None, future_regressor=None, weights: dict = {}, result_file: str = None, grouping_ids=None, validation_indexes: list = None)\n",
      " |      Train algorithm given data supplied.\n",
      " |      \n",
      " |      Args:\n",
      " |          df (pandas.DataFrame): Datetime Indexed dataframe of series, or dataframe of three columns as below.\n",
      " |          date_col (str): name of datetime column\n",
      " |          value_col (str): name of column containing the data of series.\n",
      " |          id_col (str): name of column identifying different series.\n",
      " |          future_regressor (numpy.Array): single external regressor matching train.index\n",
      " |          weights (dict): {'colname1': 2, 'colname2': 5} - increase importance of a series in metric evaluation. Any left blank assumed to have weight of 1.\n",
      " |              pass the alias 'mean' as a str ie `weights='mean'` to automatically use the mean value of a series as its weight\n",
      " |              available aliases: mean, median, min, max\n",
      " |          result_file (str): results saved on each new generation. Does not include validation rounds.\n",
      " |              \".csv\" save model results table.\n",
      " |              \".pickle\" saves full object, including ensemble information.\n",
      " |          grouping_ids (dict): currently a one-level dict containing series_id:group_id mapping.\n",
      " |              used in 0.2.x but not 0.3.x+ versions. retained for potential future use\n",
      " |  \n",
      " |  fit_data(self, df, date_col=None, value_col=None, id_col=None, future_regressor=None, weights={})\n",
      " |      Part of the setup that involves fitting the initial data but not running any models.\n",
      " |  \n",
      " |  get_metric_corr(self, percent_best=0.1)\n",
      " |      Returns a dataframe of correlation among evaluation metrics across evaluations.\n",
      " |      \n",
      " |      Args:\n",
      " |          percent_best (float): percent (ie 0.1 for 10%) of models to use, best by score first\n",
      " |  \n",
      " |  horizontal_per_generation(self)\n",
      " |  \n",
      " |  horizontal_to_df(self)\n",
      " |      helper function for plotting.\n",
      " |  \n",
      " |  import_best_model(self, import_target, enforce_model_list: bool = True, include_ensemble: bool = True)\n",
      " |      Load a best model, overriding any existing setting.\n",
      " |      \n",
      " |      Args:\n",
      " |          import_target: pd.DataFrame or file path\n",
      " |  \n",
      " |  import_results(self, filename)\n",
      " |      Add results from another run on the same data.\n",
      " |      \n",
      " |      Input can be filename with .csv or .pickle.\n",
      " |      or can be a DataFrame of model results or a full TemplateEvalObject\n",
      " |  \n",
      " |  import_template(self, filename: str, method: str = 'add_on', enforce_model_list: bool = True, include_ensemble: bool = False, include_horizontal: bool = False, force_validation: bool = False)\n",
      " |      Import a previously exported template of model parameters.\n",
      " |      Must be done before the AutoTS object is .fit().\n",
      " |      \n",
      " |      Args:\n",
      " |          filename (str): file location (or a pd.DataFrame already loaded)\n",
      " |          method (str): 'add_on' or 'only' - \"add_on\" keeps `initial_template` generated in init. \"only\" uses only this template.\n",
      " |          enforce_model_list (bool): if True, remove model types not in model_list\n",
      " |          include_ensemble (bool): if enforce_model_list is True, this specifies whether to allow ensembles anyway (otherwise they are unpacked and parts kept)\n",
      " |          include_horizontal (bool): if enforce_model_list is True, this specifies whether to allow ensembles except horizontal (overridden by keep_ensemble)\n",
      " |          force_validation (bool): if True, all models imported here will automatically get sent to full cross validation (regardless of first eval performance)\n",
      " |              weird behavior can occur wtih force_validation if another template is added later with method=='only'. In that case, model.validate_import should be erased by setting to None\n",
      " |  \n",
      " |  list_failed_model_types(self)\n",
      " |      Return a list of model types (ie ETS, LastValueNaive) that failed.\n",
      " |      If all had at least one success, then return an empty list.\n",
      " |  \n",
      " |  load_template(self, filename)\n",
      " |      Helper funciton for just loading the file part of import_template.\n",
      " |  \n",
      " |  mosaic_to_df(self)\n",
      " |      Helper function to create a readable df of models in mosaic.\n",
      " |  \n",
      " |  parse_best_model(self)\n",
      " |  \n",
      " |  plot_back_forecast(self, **kwargs)\n",
      " |  \n",
      " |  plot_backforecast(self, series=None, n_splits: int = 'auto', start_date='auto', title=None, alpha=0.25, facecolor='black', loc='upper left', **kwargs)\n",
      " |      Plot the historical data and fit forecast on historic. Out of sample in chunks = forecast_length by default.\n",
      " |      \n",
      " |      Args:\n",
      " |          series (str or list): column names of time series\n",
      " |          n_splits (int or str): \"auto\", number > 2, higher more accurate but slower\n",
      " |          start_date (datetime.datetime): or \"auto\"\n",
      " |          title (str)\n",
      " |          **kwargs passed to pd.DataFrame.plot()\n",
      " |  \n",
      " |  plot_generation_loss(self, title='Single Model Accuracy Gain Over Generations', **kwargs)\n",
      " |      Plot improvement in accuracy over generations.\n",
      " |      Note: this is only \"one size fits all\" accuracy and\n",
      " |      doesn't account for the benefits seen for ensembling.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs passed to pd.DataFrame.plot()\n",
      " |  \n",
      " |  plot_horizontal(self, max_series: int = 20, title='Model Types Chosen by Series', **kwargs)\n",
      " |      Simple plot to visualize assigned series: models.\n",
      " |      \n",
      " |      Note that for 'mosaic' ensembles, it only plots the type of the most common model_id for that series, or the first if all are mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          max_series (int): max number of points to plot\n",
      " |          **kwargs passed to pandas.plot()\n",
      " |  \n",
      " |  plot_horizontal_model_count(self, color_list=None, top_n: int = 20, title='Most Frequently Chosen Models', **kwargs)\n",
      " |      Plots most common models. Does not factor in nested in non-horizontal Ensembles.\n",
      " |  \n",
      " |  plot_horizontal_per_generation(self, title='Horizontal Ensemble Accuracy Gain (first eval sample only)', **kwargs)\n",
      " |      Plot how well the horizontal ensembles would do after each new generation. Slow.\n",
      " |  \n",
      " |  plot_horizontal_transformers(self, method='transformers', color_list=None, **kwargs)\n",
      " |      Simple plot to visualize transformers used.\n",
      " |      Note this doesn't capture transformers nested in simple ensembles.\n",
      " |      \n",
      " |      Args:\n",
      " |          method (str): 'fillna' or 'transformers' - which to plot\n",
      " |          color_list = list of colors to *sample* for bar colors. Can be names or hex.\n",
      " |          **kwargs passed to pandas.plot()\n",
      " |  \n",
      " |  plot_metric_corr(self, cols=None, percent_best=0.1)\n",
      " |      Plot correlation in results among metrics.\n",
      " |      The metrics that are highly correlated are those that mostly the unscaled ones\n",
      " |      \n",
      " |      Args:\n",
      " |          cols (list): strings of columns to show, 'all' for all\n",
      " |          percent_best (float): percent (ie 0.1 for 10%) of models to use, best by score first\n",
      " |  \n",
      " |  plot_per_series_error(self, title: str = 'Top Series Contributing Score Error', max_series: int = 10, max_name_chars: int = 25, color: str = '#ff9912', figsize=(12, 4), kind: str = 'bar', upper_clip: float = 1000, **kwargs)\n",
      " |      Plot which series are contributing most to error (Score) of final model. Avg of validations for best_model\n",
      " |      \n",
      " |      Args:\n",
      " |          title (str): plot title\n",
      " |          max_series (int): max number of series to show on plot (sorted)\n",
      " |          max_name_chars (str): if horizontal ensemble, will chop series names to this\n",
      " |          color (str): hex or name of color of plot\n",
      " |          figsize (tuple): passed through to plot axis\n",
      " |          kind (str): bar or pie\n",
      " |          upper_clip (float): set max error show to this value, to prevent unnecessary distortion\n",
      " |          **kwargs passed to pandas.plot()\n",
      " |  \n",
      " |  plot_per_series_mape(self, title: str = None, max_series: int = 10, max_name_chars: int = 25, color: str = '#ff9912', figsize=(12, 4), kind: str = 'bar', **kwargs)\n",
      " |      Plot which series are contributing most to SMAPE of final model. Avg of validations for best_model\n",
      " |      \n",
      " |      Args:\n",
      " |          title (str): plot title\n",
      " |          max_series (int): max number of series to show on plot (sorted)\n",
      " |          max_name_chars (str): if horizontal ensemble, will chop series names to this\n",
      " |          color (str): hex or name of color of plot\n",
      " |          figsize (tuple): passed through to plot axis\n",
      " |          kind (str): bar or pie\n",
      " |          **kwargs passed to pandas.plot()\n",
      " |  \n",
      " |  plot_per_series_smape(self, title: str = None, max_series: int = 10, max_name_chars: int = 25, color: str = '#ff9912', figsize=(12, 4), kind: str = 'bar', **kwargs)\n",
      " |      To be backwards compatible, not necessarily maintained, plot_per_series_mape is to be preferred.\n",
      " |  \n",
      " |  plot_transformer_failure_rate(self)\n",
      " |      Failure Rate per Transformer type (ignoring ensembles), failure may be due to other model or transformer.\n",
      " |  \n",
      " |  plot_validations(self, df_wide=None, models=None, series=None, title=None, start_date='auto', end_date='auto', subset=None, compare_horizontal=False, colors=None, include_bounds=True, alpha=0.35, start_color='darkred', end_color='#A2AD9C', **kwargs)\n",
      " |      Similar to plot_backforecast but using the model's validation segments specifically. Must reforecast.\n",
      " |      Saves results to self.validation_forecasts and caches. Set that to None to force rerun otherwise it uses stored (when models is the same).\n",
      " |      'chosen' refers to best_model_id, the model chosen to run for predict\n",
      " |      Validation sections may overlap (depending on method) which can confuse graph readers.\n",
      " |      \n",
      " |      Args:\n",
      " |          models (list): list, str, df or None, models to compare (IDs unless df of model params)\n",
      " |          series (str): time series to graph\n",
      " |          title (str): graph title\n",
      " |          start_date (str): 'auto' or datetime, place to begin graph, None for full\n",
      " |          end_date (str): 'auto' or datetime, end of graph x axis\n",
      " |          subset (str): overrides series, shows either 'best' or 'worst'\n",
      " |          compare_horizontal (bool): if True, plot horizontal ensemble versus best non-horizontal model, when available\n",
      " |          include_bounds (bool): if True (default) include the upper/lower forecast bounds\n",
      " |          start_color (str): color of vline for val start marker, None to remove vline\n",
      " |          end_color (str): color of vline for val end marker, None to remove vline\n",
      " |  \n",
      " |  predict(self, forecast_length: int = 'self', prediction_interval: float = 'self', future_regressor=None, hierarchy=None, just_point_forecast: bool = False, fail_on_forecast_nan: bool = True, verbose: int = 'self', df=None)\n",
      " |      Generate forecast data immediately following dates of index supplied to .fit().\n",
      " |      \n",
      " |      If using a model from update_fit list, with no ensembling, underlying model will not be retrained when used as below, with a single prediction interval:\n",
      " |      This designed for high speed forecasting. Full retraining is best when there is sufficient time.\n",
      " |      ```python\n",
      " |      model = AutoTS(model_list='update_fit')\n",
      " |      model.fit(df)\n",
      " |      model.predict()\n",
      " |      # for new data without retraining\n",
      " |      model.fit_data(df)\n",
      " |      model.predict()\n",
      " |      # to force retrain of best model (but not full model search)\n",
      " |      model.model = None\n",
      " |      model.fit_data(df)\n",
      " |      model.predict()\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          forecast_length (int): Number of periods of data to forecast ahead\n",
      " |          prediction_interval (float): interval of upper/lower forecasts.\n",
      " |              defaults to 'self' ie the interval specified in __init__()\n",
      " |              if prediction_interval is a list, then returns a dict of forecast objects.\n",
      " |                  {str(interval): prediction_object}\n",
      " |          future_regressor (numpy.Array): additional regressor\n",
      " |          hierarchy: Not yet implemented\n",
      " |          just_point_forecast (bool): If True, return a pandas.DataFrame of just point forecasts\n",
      " |          fail_on_forecast_nan (bool): if False, return forecasts even if NaN present, if True, raises error if any nan in forecast\n",
      " |          df (pd.DataFrame): wide style df, if present, calls fit_data with this dataframe. Recommended strongly to use model.fit_data(df) first instead as it has more args.\n",
      " |      \n",
      " |      Return:\n",
      " |          Either a PredictionObject of forecasts and metadata, or\n",
      " |          if just_point_forecast == True, a dataframe of point forecasts\n",
      " |  \n",
      " |  results(self, result_set: str = 'initial')\n",
      " |      Convenience function to return tested models table.\n",
      " |      \n",
      " |      Args:\n",
      " |          result_set (str): 'validation' or 'initial'\n",
      " |  \n",
      " |  retrieve_validation_forecasts(self, models=None, compare_horizontal=False, id_name='SeriesID', value_name='Value', interval_name='PredictionInterval')\n",
      " |  \n",
      " |  save_template(self, filename, export_template, **kwargs)\n",
      " |      Helper function for the save part of export_template.\n",
      " |  \n",
      " |  validation_agg(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_new_params(method='random')\n",
      " |      Randomly generate new parameters for the class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>temp</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>weather_main</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-01 00:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.22</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01 01:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.60</td>\n",
       "      <td>776.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01 02:00:00</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.49</td>\n",
       "      <td>666.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01 03:00:00</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.59</td>\n",
       "      <td>448.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01 04:00:00</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.26</td>\n",
       "      <td>512.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30 19:00:00</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.45</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30 20:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.76</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30 21:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.73</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>Thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30 22:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.09</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30 23:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.12</td>\n",
       "      <td>954.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     clouds_all  rain_1h  snow_1h    temp  traffic_volume  \\\n",
       "datetime                                                                    \n",
       "2016-10-01 00:00:00        20.0      0.0      0.0  286.22          1195.0   \n",
       "2016-10-01 01:00:00        20.0      0.0      0.0  285.60           776.0   \n",
       "2016-10-01 02:00:00        56.0      0.0      0.0  285.49           666.0   \n",
       "2016-10-01 03:00:00        56.0      0.0      0.0  284.59           448.0   \n",
       "2016-10-01 04:00:00        56.0      0.0      0.0  284.26           512.0   \n",
       "...                         ...      ...      ...     ...             ...   \n",
       "2018-09-30 19:00:00        75.0      0.0      0.0  283.45          3543.0   \n",
       "2018-09-30 20:00:00        90.0      0.0      0.0  282.76          2781.0   \n",
       "2018-09-30 21:00:00        90.0      0.0      0.0  282.73          2159.0   \n",
       "2018-09-30 22:00:00        90.0      0.0      0.0  282.09          1450.0   \n",
       "2018-09-30 23:00:00        90.0      0.0      0.0  282.12           954.0   \n",
       "\n",
       "                     weather_main  \n",
       "datetime                           \n",
       "2016-10-01 00:00:00        Clouds  \n",
       "2016-10-01 01:00:00        Clouds  \n",
       "2016-10-01 02:00:00        Clouds  \n",
       "2016-10-01 03:00:00        Clouds  \n",
       "2016-10-01 04:00:00        Clouds  \n",
       "...                           ...  \n",
       "2018-09-30 19:00:00        Clouds  \n",
       "2018-09-30 20:00:00        Clouds  \n",
       "2018-09-30 21:00:00  Thunderstorm  \n",
       "2018-09-30 22:00:00        Clouds  \n",
       "2018-09-30 23:00:00        Clouds  \n",
       "\n",
       "[17520 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autots import AutoTS\n",
    "from autots.datasets import load_hourly\n",
    "\n",
    "df_wide = load_hourly(long=False)\n",
    "\n",
    "# here we care most about traffic volume, all other series assumed to be weight of 1\n",
    "weights_hourly = {'traffic_volume': 20}\n",
    "\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_list = [\n",
    "    'LastValueNaive'\n",
    "]\n",
    "\n",
    "model = AutoTS(\n",
    "    forecast_length=49,\n",
    "    frequency='infer',\n",
    "    prediction_interval=0.95,\n",
    "    max_generations=5,\n",
    "    num_validations=2,\n",
    "    validation_method='seasonal 168',\n",
    "    model_list=model_list,\n",
    "    transformer_list='all',\n",
    "    models_to_validate=0.2,\n",
    "    drop_most_recent=1,\n",
    "    n_jobs='auto',\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    df_wide,\n",
    "    weights=weights_hourly,\n",
    ")\n",
    "\n",
    "prediction = model.predict()\n",
    "forecasts_df = prediction.forecast\n",
    "# prediction.long_form_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_United_States</th>\n",
       "      <th>wiki_Germany</th>\n",
       "      <th>wiki_List_of_highest-grossing_films</th>\n",
       "      <th>wiki_Jesus</th>\n",
       "      <th>wiki_Michael_Jackson</th>\n",
       "      <th>wiki_List_of_United_States_cities_by_population</th>\n",
       "      <th>wiki_Microsoft_Office</th>\n",
       "      <th>wiki_Google_Chrome</th>\n",
       "      <th>wiki_Periodic_table</th>\n",
       "      <th>wiki_Standard_deviation</th>\n",
       "      <th>...</th>\n",
       "      <th>wiki_Christmas</th>\n",
       "      <th>wiki_Chinese_New_Year</th>\n",
       "      <th>wiki_Thanksgiving</th>\n",
       "      <th>wiki_List_of_countries_that_have_gained_independence_from_the_United_Kingdom</th>\n",
       "      <th>wiki_History_of_the_hamburger</th>\n",
       "      <th>wiki_Elizabeth_II</th>\n",
       "      <th>wiki_William_Shakespeare</th>\n",
       "      <th>wiki_George_Washington</th>\n",
       "      <th>wiki_Cleopatra</th>\n",
       "      <th>wiki_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-18</th>\n",
       "      <td>59360.935119</td>\n",
       "      <td>20129.885308</td>\n",
       "      <td>23347.583926</td>\n",
       "      <td>15510.601925</td>\n",
       "      <td>26382.291754</td>\n",
       "      <td>12791.257430</td>\n",
       "      <td>15285.013813</td>\n",
       "      <td>5537.549184</td>\n",
       "      <td>17820.21599</td>\n",
       "      <td>5355.010046</td>\n",
       "      <td>...</td>\n",
       "      <td>4399.446630</td>\n",
       "      <td>1476.892424</td>\n",
       "      <td>1959.848472</td>\n",
       "      <td>925.156969</td>\n",
       "      <td>1492.342821</td>\n",
       "      <td>25930.272499</td>\n",
       "      <td>12788.120134</td>\n",
       "      <td>57341.13018</td>\n",
       "      <td>192652.101298</td>\n",
       "      <td>7.766043e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-19</th>\n",
       "      <td>59307.870239</td>\n",
       "      <td>20133.770615</td>\n",
       "      <td>23347.167853</td>\n",
       "      <td>15512.203851</td>\n",
       "      <td>26379.583508</td>\n",
       "      <td>12792.514860</td>\n",
       "      <td>15291.027627</td>\n",
       "      <td>5536.098368</td>\n",
       "      <td>17825.43198</td>\n",
       "      <td>5357.020092</td>\n",
       "      <td>...</td>\n",
       "      <td>4395.893261</td>\n",
       "      <td>1467.784847</td>\n",
       "      <td>1959.696944</td>\n",
       "      <td>925.313939</td>\n",
       "      <td>1492.685643</td>\n",
       "      <td>25880.544998</td>\n",
       "      <td>12790.240268</td>\n",
       "      <td>57364.26036</td>\n",
       "      <td>192730.202595</td>\n",
       "      <td>7.766843e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20</th>\n",
       "      <td>59254.805358</td>\n",
       "      <td>20137.655923</td>\n",
       "      <td>23346.751779</td>\n",
       "      <td>15513.805776</td>\n",
       "      <td>26376.875262</td>\n",
       "      <td>12793.772290</td>\n",
       "      <td>15297.041440</td>\n",
       "      <td>5534.647551</td>\n",
       "      <td>17830.64797</td>\n",
       "      <td>5359.030138</td>\n",
       "      <td>...</td>\n",
       "      <td>4392.339891</td>\n",
       "      <td>1458.677271</td>\n",
       "      <td>1959.545416</td>\n",
       "      <td>925.470908</td>\n",
       "      <td>1493.028464</td>\n",
       "      <td>25830.817497</td>\n",
       "      <td>12792.360402</td>\n",
       "      <td>57387.39054</td>\n",
       "      <td>192808.303893</td>\n",
       "      <td>7.767644e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-21</th>\n",
       "      <td>59201.740477</td>\n",
       "      <td>20141.541231</td>\n",
       "      <td>23346.335705</td>\n",
       "      <td>15515.407702</td>\n",
       "      <td>26374.167015</td>\n",
       "      <td>12795.029720</td>\n",
       "      <td>15303.055253</td>\n",
       "      <td>5533.196735</td>\n",
       "      <td>17835.86396</td>\n",
       "      <td>5361.040184</td>\n",
       "      <td>...</td>\n",
       "      <td>4388.786522</td>\n",
       "      <td>1449.569694</td>\n",
       "      <td>1959.393889</td>\n",
       "      <td>925.627878</td>\n",
       "      <td>1493.371285</td>\n",
       "      <td>25781.089996</td>\n",
       "      <td>12794.480536</td>\n",
       "      <td>57410.52072</td>\n",
       "      <td>192886.405190</td>\n",
       "      <td>7.768444e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-22</th>\n",
       "      <td>59148.675596</td>\n",
       "      <td>20145.426538</td>\n",
       "      <td>23345.919632</td>\n",
       "      <td>15517.009627</td>\n",
       "      <td>26371.458769</td>\n",
       "      <td>12796.287149</td>\n",
       "      <td>15309.069067</td>\n",
       "      <td>5531.745919</td>\n",
       "      <td>17841.07995</td>\n",
       "      <td>5363.050230</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.233152</td>\n",
       "      <td>1440.462118</td>\n",
       "      <td>1959.242361</td>\n",
       "      <td>925.784847</td>\n",
       "      <td>1493.714106</td>\n",
       "      <td>25731.362495</td>\n",
       "      <td>12796.600670</td>\n",
       "      <td>57433.65090</td>\n",
       "      <td>192964.506488</td>\n",
       "      <td>7.769244e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-23</th>\n",
       "      <td>59095.610716</td>\n",
       "      <td>20149.311846</td>\n",
       "      <td>23345.503558</td>\n",
       "      <td>15518.611553</td>\n",
       "      <td>26368.750523</td>\n",
       "      <td>12797.544579</td>\n",
       "      <td>15315.082880</td>\n",
       "      <td>5530.295103</td>\n",
       "      <td>17846.29594</td>\n",
       "      <td>5365.060276</td>\n",
       "      <td>...</td>\n",
       "      <td>4381.679782</td>\n",
       "      <td>1431.354542</td>\n",
       "      <td>1959.090833</td>\n",
       "      <td>925.941817</td>\n",
       "      <td>1494.056928</td>\n",
       "      <td>25681.634994</td>\n",
       "      <td>12798.720804</td>\n",
       "      <td>57456.78108</td>\n",
       "      <td>193042.607786</td>\n",
       "      <td>7.770044e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-24</th>\n",
       "      <td>59042.545835</td>\n",
       "      <td>20153.197154</td>\n",
       "      <td>23345.087484</td>\n",
       "      <td>15520.213478</td>\n",
       "      <td>26366.042277</td>\n",
       "      <td>12798.802009</td>\n",
       "      <td>15321.096693</td>\n",
       "      <td>5528.844286</td>\n",
       "      <td>17851.51193</td>\n",
       "      <td>5367.070322</td>\n",
       "      <td>...</td>\n",
       "      <td>4378.126413</td>\n",
       "      <td>1422.246965</td>\n",
       "      <td>1958.939305</td>\n",
       "      <td>926.098786</td>\n",
       "      <td>1494.399749</td>\n",
       "      <td>25631.907493</td>\n",
       "      <td>12800.840938</td>\n",
       "      <td>57479.91126</td>\n",
       "      <td>193120.709083</td>\n",
       "      <td>7.770845e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-25</th>\n",
       "      <td>58989.480954</td>\n",
       "      <td>20157.082461</td>\n",
       "      <td>23344.671411</td>\n",
       "      <td>15521.815404</td>\n",
       "      <td>26363.334031</td>\n",
       "      <td>12800.059439</td>\n",
       "      <td>15327.110506</td>\n",
       "      <td>5527.393470</td>\n",
       "      <td>17856.72792</td>\n",
       "      <td>5369.080368</td>\n",
       "      <td>...</td>\n",
       "      <td>4374.573043</td>\n",
       "      <td>1413.139389</td>\n",
       "      <td>1958.787777</td>\n",
       "      <td>926.255756</td>\n",
       "      <td>1494.742570</td>\n",
       "      <td>25582.179992</td>\n",
       "      <td>12802.961072</td>\n",
       "      <td>57503.04144</td>\n",
       "      <td>193198.810381</td>\n",
       "      <td>7.771645e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-26</th>\n",
       "      <td>58936.416074</td>\n",
       "      <td>20160.967769</td>\n",
       "      <td>23344.255337</td>\n",
       "      <td>15523.417329</td>\n",
       "      <td>26360.625785</td>\n",
       "      <td>12801.316869</td>\n",
       "      <td>15333.124320</td>\n",
       "      <td>5525.942654</td>\n",
       "      <td>17861.94391</td>\n",
       "      <td>5371.090414</td>\n",
       "      <td>...</td>\n",
       "      <td>4371.019674</td>\n",
       "      <td>1404.031812</td>\n",
       "      <td>1958.636249</td>\n",
       "      <td>926.412725</td>\n",
       "      <td>1495.085391</td>\n",
       "      <td>25532.452491</td>\n",
       "      <td>12805.081206</td>\n",
       "      <td>57526.17162</td>\n",
       "      <td>193276.911679</td>\n",
       "      <td>7.772445e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-27</th>\n",
       "      <td>58883.351193</td>\n",
       "      <td>20164.853077</td>\n",
       "      <td>23343.839263</td>\n",
       "      <td>15525.019255</td>\n",
       "      <td>26357.917539</td>\n",
       "      <td>12802.574299</td>\n",
       "      <td>15339.138133</td>\n",
       "      <td>5524.491838</td>\n",
       "      <td>17867.15990</td>\n",
       "      <td>5373.100460</td>\n",
       "      <td>...</td>\n",
       "      <td>4367.466304</td>\n",
       "      <td>1394.924236</td>\n",
       "      <td>1958.484722</td>\n",
       "      <td>926.569694</td>\n",
       "      <td>1495.428213</td>\n",
       "      <td>25482.724990</td>\n",
       "      <td>12807.201339</td>\n",
       "      <td>57549.30180</td>\n",
       "      <td>193355.012976</td>\n",
       "      <td>7.773246e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            wiki_United_States  wiki_Germany  \\\n",
       "2023-07-18        59360.935119  20129.885308   \n",
       "2023-07-19        59307.870239  20133.770615   \n",
       "2023-07-20        59254.805358  20137.655923   \n",
       "2023-07-21        59201.740477  20141.541231   \n",
       "2023-07-22        59148.675596  20145.426538   \n",
       "2023-07-23        59095.610716  20149.311846   \n",
       "2023-07-24        59042.545835  20153.197154   \n",
       "2023-07-25        58989.480954  20157.082461   \n",
       "2023-07-26        58936.416074  20160.967769   \n",
       "2023-07-27        58883.351193  20164.853077   \n",
       "\n",
       "            wiki_List_of_highest-grossing_films    wiki_Jesus  \\\n",
       "2023-07-18                         23347.583926  15510.601925   \n",
       "2023-07-19                         23347.167853  15512.203851   \n",
       "2023-07-20                         23346.751779  15513.805776   \n",
       "2023-07-21                         23346.335705  15515.407702   \n",
       "2023-07-22                         23345.919632  15517.009627   \n",
       "2023-07-23                         23345.503558  15518.611553   \n",
       "2023-07-24                         23345.087484  15520.213478   \n",
       "2023-07-25                         23344.671411  15521.815404   \n",
       "2023-07-26                         23344.255337  15523.417329   \n",
       "2023-07-27                         23343.839263  15525.019255   \n",
       "\n",
       "            wiki_Michael_Jackson  \\\n",
       "2023-07-18          26382.291754   \n",
       "2023-07-19          26379.583508   \n",
       "2023-07-20          26376.875262   \n",
       "2023-07-21          26374.167015   \n",
       "2023-07-22          26371.458769   \n",
       "2023-07-23          26368.750523   \n",
       "2023-07-24          26366.042277   \n",
       "2023-07-25          26363.334031   \n",
       "2023-07-26          26360.625785   \n",
       "2023-07-27          26357.917539   \n",
       "\n",
       "            wiki_List_of_United_States_cities_by_population  \\\n",
       "2023-07-18                                     12791.257430   \n",
       "2023-07-19                                     12792.514860   \n",
       "2023-07-20                                     12793.772290   \n",
       "2023-07-21                                     12795.029720   \n",
       "2023-07-22                                     12796.287149   \n",
       "2023-07-23                                     12797.544579   \n",
       "2023-07-24                                     12798.802009   \n",
       "2023-07-25                                     12800.059439   \n",
       "2023-07-26                                     12801.316869   \n",
       "2023-07-27                                     12802.574299   \n",
       "\n",
       "            wiki_Microsoft_Office  wiki_Google_Chrome  wiki_Periodic_table  \\\n",
       "2023-07-18           15285.013813         5537.549184          17820.21599   \n",
       "2023-07-19           15291.027627         5536.098368          17825.43198   \n",
       "2023-07-20           15297.041440         5534.647551          17830.64797   \n",
       "2023-07-21           15303.055253         5533.196735          17835.86396   \n",
       "2023-07-22           15309.069067         5531.745919          17841.07995   \n",
       "2023-07-23           15315.082880         5530.295103          17846.29594   \n",
       "2023-07-24           15321.096693         5528.844286          17851.51193   \n",
       "2023-07-25           15327.110506         5527.393470          17856.72792   \n",
       "2023-07-26           15333.124320         5525.942654          17861.94391   \n",
       "2023-07-27           15339.138133         5524.491838          17867.15990   \n",
       "\n",
       "            wiki_Standard_deviation  ...  wiki_Christmas  \\\n",
       "2023-07-18              5355.010046  ...     4399.446630   \n",
       "2023-07-19              5357.020092  ...     4395.893261   \n",
       "2023-07-20              5359.030138  ...     4392.339891   \n",
       "2023-07-21              5361.040184  ...     4388.786522   \n",
       "2023-07-22              5363.050230  ...     4385.233152   \n",
       "2023-07-23              5365.060276  ...     4381.679782   \n",
       "2023-07-24              5367.070322  ...     4378.126413   \n",
       "2023-07-25              5369.080368  ...     4374.573043   \n",
       "2023-07-26              5371.090414  ...     4371.019674   \n",
       "2023-07-27              5373.100460  ...     4367.466304   \n",
       "\n",
       "            wiki_Chinese_New_Year  wiki_Thanksgiving  \\\n",
       "2023-07-18            1476.892424        1959.848472   \n",
       "2023-07-19            1467.784847        1959.696944   \n",
       "2023-07-20            1458.677271        1959.545416   \n",
       "2023-07-21            1449.569694        1959.393889   \n",
       "2023-07-22            1440.462118        1959.242361   \n",
       "2023-07-23            1431.354542        1959.090833   \n",
       "2023-07-24            1422.246965        1958.939305   \n",
       "2023-07-25            1413.139389        1958.787777   \n",
       "2023-07-26            1404.031812        1958.636249   \n",
       "2023-07-27            1394.924236        1958.484722   \n",
       "\n",
       "            wiki_List_of_countries_that_have_gained_independence_from_the_United_Kingdom  \\\n",
       "2023-07-18                                         925.156969                              \n",
       "2023-07-19                                         925.313939                              \n",
       "2023-07-20                                         925.470908                              \n",
       "2023-07-21                                         925.627878                              \n",
       "2023-07-22                                         925.784847                              \n",
       "2023-07-23                                         925.941817                              \n",
       "2023-07-24                                         926.098786                              \n",
       "2023-07-25                                         926.255756                              \n",
       "2023-07-26                                         926.412725                              \n",
       "2023-07-27                                         926.569694                              \n",
       "\n",
       "            wiki_History_of_the_hamburger  wiki_Elizabeth_II  \\\n",
       "2023-07-18                    1492.342821       25930.272499   \n",
       "2023-07-19                    1492.685643       25880.544998   \n",
       "2023-07-20                    1493.028464       25830.817497   \n",
       "2023-07-21                    1493.371285       25781.089996   \n",
       "2023-07-22                    1493.714106       25731.362495   \n",
       "2023-07-23                    1494.056928       25681.634994   \n",
       "2023-07-24                    1494.399749       25631.907493   \n",
       "2023-07-25                    1494.742570       25582.179992   \n",
       "2023-07-26                    1495.085391       25532.452491   \n",
       "2023-07-27                    1495.428213       25482.724990   \n",
       "\n",
       "            wiki_William_Shakespeare  wiki_George_Washington  wiki_Cleopatra  \\\n",
       "2023-07-18              12788.120134             57341.13018   192652.101298   \n",
       "2023-07-19              12790.240268             57364.26036   192730.202595   \n",
       "2023-07-20              12792.360402             57387.39054   192808.303893   \n",
       "2023-07-21              12794.480536             57410.52072   192886.405190   \n",
       "2023-07-22              12796.600670             57433.65090   192964.506488   \n",
       "2023-07-23              12798.720804             57456.78108   193042.607786   \n",
       "2023-07-24              12800.840938             57479.91126   193120.709083   \n",
       "2023-07-25              12802.961072             57503.04144   193198.810381   \n",
       "2023-07-26              12805.081206             57526.17162   193276.911679   \n",
       "2023-07-27              12807.201339             57549.30180   193355.012976   \n",
       "\n",
       "                wiki_all  \n",
       "2023-07-18  7.766043e+08  \n",
       "2023-07-19  7.766843e+08  \n",
       "2023-07-20  7.767644e+08  \n",
       "2023-07-21  7.768444e+08  \n",
       "2023-07-22  7.769244e+08  \n",
       "2023-07-23  7.770044e+08  \n",
       "2023-07-24  7.770845e+08  \n",
       "2023-07-25  7.771645e+08  \n",
       "2023-07-26  7.772445e+08  \n",
       "2023-07-27  7.773246e+08  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autots import load_daily, model_forecast\n",
    "\n",
    "\n",
    "df = load_daily(long=False)  # long or non-numeric data won't work with this function\n",
    "df_forecast = model_forecast(\n",
    "    model_name=\"AverageValueNaive\",\n",
    "    model_param_dict={'method': 'Mean'},\n",
    "    model_transform_dict={\n",
    "        'fillna': 'mean',\n",
    "        'transformations': {'0': 'DifferencedTransformer'},\n",
    "        'transformation_params': {'0': {}}\n",
    "    },\n",
    "    df_train=df,\n",
    "    forecast_length=12,\n",
    "    frequency='infer',\n",
    "    prediction_interval=0.9,\n",
    "    no_negatives=False,\n",
    "    # future_regressor_train=future_regressor_train2d,\n",
    "    # future_regressor_forecast=future_regressor_forecast2d,\n",
    "    random_seed=321,\n",
    "    verbose=0,\n",
    "    n_jobs=\"auto\",\n",
    ")\n",
    "df_forecast.forecast.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
